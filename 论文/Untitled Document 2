vinsfusion
1.Vins-Fusion主题框架，数据流分析；
2.前端：基于LK光流法跟踪特征法的原理、源码细节处理及对比特征点法的优劣；
3.后端：基于BA优化的位姿估计，主要包括：如何构建IMU残差、左右目残差、单目前后两帧残差，前帧左目当前帧右目残差；
4.回环检测：基于词袋模型DBoW回环检测分析；
5.其它：外参矩阵实时估计、3d-2d PNP求解、三角化、初始化如何实现位姿对齐等。


////////////
KLT稀疏光流算法
它是空间运动物体在观察成像平面上的像素运动的瞬时速度，是利用图像序列中像素在时间域上的变化以及相邻帧之间的相关性来找到上一帧跟当前帧之间存在的对应关系，从而计算出相邻帧之间物体的运动信息的一种方法。

/home/sbim/Desktop/素材/Feishu20240325-115953.mp4

KLT算法的核心是基于两个基本假设：

亮度恒定假设：即一个点在连续的两帧图像中的亮度（或颜色）不会改变。
小运动假设：连续的两帧图像中物体的移动距离是小的，因此物体的运动可以用一阶泰勒级数展开来近似。
算法的工作流程大致如下：

特征点选择：首先，在图像中选择一些好的特征点（角点）。Tomasi和Kanade提出的“最小特征值”方法经常被用来选择这些特征点。
计算光流：对于每一个特征点，算法在下一帧图像中寻找对应的点，这个过程通过最小化两帧之间的图像差异（例如使用最小二乘法）来实现。这里，图像的局部窗口内的所有点被假设具有相同的运动。
特征点更新：更新特征点的位置到它们在新一帧中的位置。
迭代：重复步骤2和3，为视频序列中的每一帧图像计算和更新特征点的运动。

///////////////
///////////////
FGO表示因子图优化，BA表示束调整，SWO表示滑动窗口优
化，PGO表示位姿图优化

语义slam：Semantic SLAM

//////////////////////////////
//////////////////////////////
深蓝学院学slam
https://www.shenlanxueyuan.com/search?q=slam
https://www.shenlanxueyuan.com/open/course/109/lesson/99/liveToVideoPreview

讲vinsfusion讲的很好的
https://blog.csdn.net/iwanderu/article/details/104617829
https://zhi-ang.github.io/2019/09/11/vins_fusion/
传感器只能提供局部观测，限制了其应用场景：

第一个问题是局部观测数据缺乏全局约束，当我们每次在不同的位置运行算法时，都会得到不同坐标系下的定位和建图结果，因而难以将这些测量结果结合起来，形成全局效果。
第二个问题是基于局部观测的估计算法必然存在累计漂移，尽管回环检测可以一定程度上消除漂移，但是对于数据量较大的大范围场景，算法依然难以处理。











